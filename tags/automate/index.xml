<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Automate on Coder</title><link>https://blog.mkdef.com/tags/automate/</link><description>Recent content in Automate on Coder</description><generator>Hugo -- gohugo.io</generator><language>en</language><lastBuildDate>Mon, 11 Apr 2022 15:16:38 +0800</lastBuildDate><atom:link href="https://blog.mkdef.com/tags/automate/index.xml" rel="self" type="application/rss+xml"/><item><title>用自动机和Rust索引16亿条记录[TBD]</title><link>https://blog.mkdef.com/posts/automata/</link><pubDate>Mon, 11 Apr 2022 15:16:38 +0800</pubDate><guid>https://blog.mkdef.com/posts/automata/</guid><description>原文: Index 1,600,000,000 Keys with Automata and Rust
看上去有限状态机在除了表达式计算之外的一些事情上也很有用。有限状态机也可以用来压缩表示有序集合或者字符串映射，并且能够非常快的在上面进行检索。
在这篇文章里，我会告诉你如何用有限状态机作为表示有序集合和映射的数据结构。包括介绍一个Rust的实现：fst。它包含完整的API文档。我也会展示给你如何用一个简单的命令行工具来构建他们。最后，我会以讨论几个索引16亿条July 2015 Common Crawl Archive网址的实验
这篇文章展示的技术也是Lucene用来表示部分倒排索引的方法。
在这个过程中，我们会谈到内存映射，自动机和正则匹配，Levenshtein距离下的模糊检索和流式集合操作。
目标读者： 熟悉编程和基础的数据结构。不要求有自动机理论或者Rust的经验。
预告片 作为预告，我们先展示一下我们的成果。我们先快速看一个例子。我们先不看16亿字符串，我们先考虑1600w维基百科文章标题(384M)。这是我们用来索引他们的方法：
$ time fst set --sorted wiki-titles wiki-titles.fst real 0m18.310 最终的索引wiki-titles.fst是157M。作为比较，gzip花了12秒并且压缩到了91m。 （对于某些数据集，我们的编码方式可以同时在速度和压缩率上超过gzip）。
然而，这是一些gzip做不了的事情：快速找到所有以Homer the开头的文章标题:
$ time fst grep wiki-titles.fst &amp;#39;Homer the.*&amp;#39; Homer the Clown Homer the Father Homer the Great Homer the Happy Ghost Homer the Heretic Homer the Moe Homer the Smithers ... real 0m0.023s 作为比较，grep 在原始未压缩的数据上用了0.</description></item></channel></rss>